{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7I5_dQIf7NfO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"/content/test.xlsx\"\n",
    "df_bonus = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sA1lhqio9bZv"
   },
   "outputs": [],
   "source": [
    "y_estimé=df_bonus['y_estimé']\n",
    "y=df_bonus['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bwz32DlaaAI8"
   },
   "source": [
    "##un fonction qui permet de calculer lan matrice de confusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9roTCLDLZBO",
    "outputId": "f5ab214c-f3c4-4752-8fc2-070f75bec313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la matrice de confusion est :\n",
      "[[24.  0.  0.]\n",
      " [ 0. 26.  0.]\n",
      " [ 0.  1. 24.]]\n"
     ]
    }
   ],
   "source": [
    "T1= np.zeros((3,3))\n",
    "\n",
    "for i in range(len(y_estimé)):\n",
    "\n",
    "  if y[i]==1 :\n",
    "    if y_estimé[i]==y[i] :\n",
    "      T1[0][0]+=1\n",
    "\n",
    "    if y_estimé[i]!=y[i] and y_estimé[i]==2:\n",
    "      T1[0][1]+=1\n",
    "\n",
    "    if y_estimé[i]!=y[i] and y_estimé[i]==3:\n",
    "      T1[0][2]+=1\n",
    "\n",
    "  if y[i]==2 :\n",
    "    if y_estimé[i]==y[i] :\n",
    "      T1[1][1]+=1\n",
    "\n",
    "    if y_estimé[i]!=y[i] and y_estimé[i]==1:\n",
    "      T1[1][0]+=1\n",
    "\n",
    "    if y_estimé[i]!=y[i] and y_estimé[i]==3:\n",
    "      T1[1][2]+=1\n",
    "\n",
    "  if y[i]==3 :\n",
    "    if y_estimé[i]==y[i] :\n",
    "      T1[2][2]+=1\n",
    "\n",
    "    if y_estimé[i]!=y[i] and y_estimé[i]==1:\n",
    "      T1[2][0]+=1\n",
    "\n",
    "    if y_estimé[i]!=y[i] and y_estimé[i]==2:\n",
    "      T1[2][1]+=1\n",
    "\n",
    "print(\"la matrice de confusion est :\")\n",
    "print(T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liy6WvQbLYkD",
    "outputId": "f0894998-e880-4596-a8ee-b5709059dc0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les scores pour  chaque class:\n",
      "[[24. 51.  0.  0.]\n",
      " [26. 48.  1.  0.]\n",
      " [24. 50.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "def conf_matrix_values(confusion_matrix):\n",
    "\n",
    "    metric_matrix = np.zeros((confusion_matrix.shape[0], 4))\n",
    "    dim = confusion_matrix.shape[0]\n",
    "    for i in range(dim):\n",
    "        metric_matrix[i, 0] = confusion_matrix[i, i]\n",
    "        metric_matrix[i, 1] = np.sum(confusion_matrix[:, :]) - np.sum(confusion_matrix[:, i]) - np.sum(confusion_matrix[i, :]) + confusion_matrix[i, i]\n",
    "        metric_matrix[i, 2] = np.sum(confusion_matrix[:, i]) - confusion_matrix[i, i]\n",
    "        metric_matrix[i, 3] = np.sum(confusion_matrix[i, :]) - confusion_matrix[i, i]\n",
    "\n",
    "    return metric_matrix\n",
    "\n",
    "metric_matrix = conf_matrix_values(T1)\n",
    "print(\"les scores pour  chaque class:\")\n",
    "print(metric_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfMOcErpaT9U"
   },
   "source": [
    "#calcule de  la précision globale et par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Jkq3DiRRgCE",
    "outputId": "1c4ad15c-c566-40f9-bfc4-80caff4a8bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision est [1.         0.96296296 1.        ]\n",
      "Précision moyenne 0.9876543209876543\n"
     ]
    }
   ],
   "source": [
    "Precision=np.zeros(3)\n",
    "for i in range(3):\n",
    "\n",
    "  Precision[i]=metric_matrix[i][0]/(metric_matrix[i][0]+metric_matrix[i][2])\n",
    "\n",
    "print(\"Précision pour chaque classe est\" ,Precision)\n",
    "print(\"Précision globale\" ,np.mean(Precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc94CZY2aTZL"
   },
   "source": [
    "## calcule du rappel globale et par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QvUS7NTcTOY_",
    "outputId": "4c68a698-5e04-4d13-de31-0e59ef22dd98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rappel est [1.   1.   0.96]\n",
      "rappel moyenne 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "Recall=np.zeros(3)\n",
    "for i in range(3):\n",
    "\n",
    "  Recall[i]=metric_matrix[i][0]/(metric_matrix[i][0]+metric_matrix[i][3])\n",
    "\n",
    "print(\"rappel pour chaque classe est\" ,Recall)\n",
    "print(\"rappel globale\" ,np.mean(Recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huCoNstsap9j"
   },
   "source": [
    "##calcule du F_score globale et par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJGpvhKfTroN",
    "outputId": "df54bebf-82ab-40fd-eb8a-aa2570fa8c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score pour est [1.         0.98113208 0.97959184]\n",
      "Fscore  moyenne 0.986907970735464\n"
     ]
    }
   ],
   "source": [
    "F_mesure=np.zeros(3)\n",
    "beta=1\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "  F_mesure[i]=(1+beta*beta)*((Recall[i]*Precision[i])/(beta*beta*Precision[i]+Recall[i]))\n",
    "\n",
    "print(\"F score pour pour chaque classe est\" ,F_mesure)\n",
    "print(\"F score  gobale\" ,np.mean(F_mesure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxEzxBFR6ppu"
   },
   "source": [
    "##Calcul de la précision avec sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mxDtxmfVvoF",
    "outputId": "b15069f2-66e2-49b9-f166-8fcfc89472e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        24\n",
      "           2       0.96      1.00      0.98        26\n",
      "           3       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.99        75\n",
      "   macro avg       0.99      0.99      0.99        75\n",
      "weighted avg       0.99      0.99      0.99        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(metrics.classification_report(y, y_estimé))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEL7-06RYC8r"
   },
   "source": [
    "D'apres les résultats obtenu on remarque que la marice de confusion nous permet  de voir\n",
    "facilement si l’algorithme d’apprentissage confond deux classes. Chaque\n",
    "colonne de la matrice de confusion représente les instances d’une classe estimé,\n",
    "tandis que chaque linge représente des instances d’une classe réelle."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
